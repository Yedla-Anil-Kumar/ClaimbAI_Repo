# Example: diverse MLflow usage patterns (SDK, autolog, client, env, CI, K8s)
import os, json, mlflow, mlflow.sklearn
from mlflow.tracking import MlflowClient

# env-based config (common in prod)
os.environ["MLFLOW_TRACKING_URI"] = "https://mlflow.acme.internal"

mlflow.set_experiment("credit_risk_v2")

# autolog as an alternative to manual log_* calls
mlflow.sklearn.autolog()

with mlflow.start_run(run_name="xgb-nightly") as run:
    # batch logging via client (equivalent to many log_* calls)
    client = MlflowClient()
    client.log_batch(
        run_id=run.info.run_id,
        metrics=[{"key": "auc", "value": 0.914, "timestamp": 1731000000000}],
        params=[{"key": "tree_method", "value": "hist"}],
        tags=[{"key": "stage", "value": "train"}],
    )
    # artifacts (metrics file) â€“ also counts as structured logging
    with open("metrics.json", "w") as f:
        json.dump({"f1": 0.88, "precision": 0.91}, f)
    mlflow.log_artifact("metrics.json", artifact_path="reports")

# registry usage (promotion flow noted in CI)
# mlflow.register_model(f"runs:/{run.info.run_id}/model", "credit_risk")
# CI/CD (GitHub Actions) promotes to Staging, then K8s serve via mlflow model-serving image

# MLproject indicator (alternate config style)
# name: credit-risk
# conda_env: conda.yaml
# entry_points:
#   train:
#     parameters:
#       max_depth: {type: int, default: 6}
#     command: "python train.py --max_depth {max_depth}"

# K8s hints (helm chart referencing MLflow model server)
# charts/mlflow-serving/values.yaml -> image: mlflow/model-server:latest
